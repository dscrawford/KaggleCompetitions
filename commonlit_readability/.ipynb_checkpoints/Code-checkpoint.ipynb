{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "# sklearn utils\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Network\n",
    "####\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, seq_len, h_in, device):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.num_layers = 1\n",
    "        self.seq_len    = seq_len\n",
    "        self.h_in       = h_in\n",
    "        self.device     = device\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size = self.seq_len, \n",
    "                            hidden_size = self.h_in, \n",
    "                            num_layers = self.num_layers\n",
    "                           )\n",
    "        \n",
    "        self.fc1 = nn.Linear(h_in, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 16)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc = nn.Linear(16, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, (hn, cn) = self.lstm(x.float())\n",
    "        hn = hn.view(-1, self.h_in)\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Model Trainer\n",
    "#####\n",
    "\n",
    "class ModelBuilder:\n",
    "    def __init__(self, nlp, seq_len):\n",
    "        self.seq_len = seq_len\n",
    "        self.nlp = nlp\n",
    "        self.embed_dim = 300\n",
    "        \n",
    "    def get_features(self, texts):\n",
    "        with self.nlp.disable_pipes():\n",
    "            nlp_texts = [self.nlp(text) for text in texts]\n",
    "        feats = np.zeros((len(nlp_texts), self.seq_len, self.embed_dim))\n",
    "\n",
    "        for i in range(len(nlp_texts)):\n",
    "            text = nlp_texts[i]\n",
    "            feats[i][0:min(len(text), self.seq_len)] = [word.vector for word in text[0:min(len(text), self.seq_len)]]\n",
    "            \n",
    "        return feats\n",
    "    \n",
    "    def get_data_loaders(self, feats, labels, test_size=0.1, train_args={}, test_args={}):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(feats, labels, test_size=test_size)\n",
    "        \n",
    "        dataloader_train = DataLoader(list(zip(X_train, y_train)), **train_args)\n",
    "        dataloader_test  = DataLoader(list(zip(X_test, y_test)), **test_args)\n",
    "        \n",
    "        return dataloader_train, dataloader_test\n",
    "        \n",
    "        \n",
    "    def train(self, model, train, test, optimizer, criterion, num_epochs, device):\n",
    "        train_losses = []\n",
    "        test_losses  = []\n",
    "        \n",
    "        model = model.to(device)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            sleep(1)\n",
    "            train_loss = 0\n",
    "            test_loss = 0\n",
    "            n = 0\n",
    "            n_test = 0\n",
    "            \n",
    "            tq = tqdm(train)\n",
    "            it_str = 'Epoch {0: d}, Train MSE: {1: 5.6f}'\n",
    "            tq.set_description(it_str.format(epoch + 1, float(0)))\n",
    "            \n",
    "            \n",
    "            model.train()\n",
    "            for inputs, targets in tq:\n",
    "                inputs, targets = inputs.to(device).float(), targets.to(device).float()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item() * len(inputs)\n",
    "                n += len(inputs)\n",
    "                tq.set_description(it_str.format(epoch + 1, train_loss / n))\n",
    "                \n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in test:\n",
    "                    inputs, targets = inputs.to(device).float(), targets.to(device).float()\n",
    "                    outputs = model(inputs)\n",
    "                    \n",
    "  \n",
    "                    \n",
    "                    loss = criterion(outputs, targets)\n",
    "                    \n",
    "                    test_loss += loss.item() * len(inputs)\n",
    "                    n_test += len(inputs)\n",
    "            \n",
    "            print('Test MSE: {0: 5.6f}, Test RMSE: {1: 5.6f}'.format(test_loss / n_test, np.sqrt(test_loss / n_test)))\n",
    "            \n",
    "            train_losses.append(train_loss)\n",
    "            test_losses.append(test_loss)\n",
    "        \n",
    "        return model, {'train_losses': train_losses, 'test_losses': test_losses}\n",
    "                    \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = './'\n",
    "train_path = wd + 'train.csv'\n",
    "random_state = 1\n",
    "seq_len = 300\n",
    "h_in = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2834.000000\n",
       "mean       -0.959319\n",
       "std         1.033579\n",
       "min        -3.676268\n",
       "25%        -1.690320\n",
       "50%        -0.912190\n",
       "75%        -0.202540\n",
       "max         1.711390\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.464009\n",
       "1       0.480805\n",
       "2       0.476676\n",
       "3       0.450007\n",
       "4       0.510845\n",
       "          ...   \n",
       "2829    0.646900\n",
       "2830    0.535648\n",
       "2831    0.483866\n",
       "2832    0.514128\n",
       "2833    0.512379\n",
       "Name: standard_error, Length: 2834, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['standard_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist1 = plt.hist(data['target'], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Model(seq_len, h_in, device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "modelbuild = ModelBuilder(nlp, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = modelbuild.get_features(data['excerpt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = modelbuild.get_data_loaders(feat, data['target'], 0.1, \n",
    "                                          train_args={'batch_size':8, 'shuffle':True},\n",
    "                                          test_args={'batch_size': 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1, Train MSE:  0.000000:   0%|          | 0/319 [00:00<?, ?it/s]/home/daniel/.conda/envs/ml/lib/python3.7/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([300, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch  1, Train MSE:  1.092215:  97%|█████████▋| 310/319 [00:01<00:00, 179.88it/s]/home/daniel/.conda/envs/ml/lib/python3.7/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([6])) that is different to the input size (torch.Size([300, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch  1, Train MSE:  1.091791: 100%|██████████| 319/319 [00:01<00:00, 176.98it/s]\n",
      "/home/daniel/.conda/envs/ml/lib/python3.7/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([300, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch  2, Train MSE:  1.190188:   6%|▌         | 19/319 [00:00<00:01, 184.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.051995, Test RMSE:  1.025668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  2, Train MSE:  1.072562: 100%|██████████| 319/319 [00:01<00:00, 182.66it/s]\n",
      "Epoch  3, Train MSE:  1.099136:   6%|▌         | 19/319 [00:00<00:01, 183.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.046224, Test RMSE:  1.022851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  3, Train MSE:  1.072135: 100%|██████████| 319/319 [00:01<00:00, 178.53it/s]\n",
      "Epoch  4, Train MSE:  1.117842:   6%|▌         | 19/319 [00:00<00:01, 179.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.045015, Test RMSE:  1.022260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  4, Train MSE:  1.071148: 100%|██████████| 319/319 [00:01<00:00, 182.61it/s]\n",
      "Epoch  5, Train MSE:  1.049455:   4%|▍         | 12/319 [00:00<00:02, 117.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.044325, Test RMSE:  1.021922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  5, Train MSE:  1.073008: 100%|██████████| 319/319 [00:01<00:00, 178.59it/s]\n",
      "Epoch  6, Train MSE:  1.137629:   6%|▌         | 19/319 [00:00<00:01, 183.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.042984, Test RMSE:  1.021266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  6, Train MSE:  1.070761: 100%|██████████| 319/319 [00:01<00:00, 182.37it/s]\n",
      "Epoch  7, Train MSE:  1.142144:   6%|▌         | 19/319 [00:00<00:01, 180.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.042520, Test RMSE:  1.021039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  7, Train MSE:  1.071195: 100%|██████████| 319/319 [00:01<00:00, 180.60it/s]\n",
      "Epoch  8, Train MSE:  1.151825:   6%|▌         | 18/319 [00:00<00:01, 179.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.041751, Test RMSE:  1.020662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  8, Train MSE:  1.069905: 100%|██████████| 319/319 [00:01<00:00, 181.67it/s]\n",
      "Epoch  9, Train MSE:  1.098154:   6%|▌         | 19/319 [00:00<00:01, 181.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.040796, Test RMSE:  1.020194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  9, Train MSE:  1.071102: 100%|██████████| 319/319 [00:01<00:00, 181.13it/s]\n",
      "Epoch  10, Train MSE:  1.095249:   6%|▌         | 19/319 [00:00<00:01, 180.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.040882, Test RMSE:  1.020236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  10, Train MSE:  1.070032: 100%|██████████| 319/319 [00:01<00:00, 178.90it/s]\n",
      "Epoch  11, Train MSE:  1.217733:   6%|▋         | 20/319 [00:00<00:01, 190.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.046356, Test RMSE:  1.022916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  11, Train MSE:  1.068549: 100%|██████████| 319/319 [00:01<00:00, 182.14it/s]\n",
      "Epoch  12, Train MSE:  1.061154:   6%|▌         | 19/319 [00:00<00:01, 182.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.040402, Test RMSE:  1.020001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  12, Train MSE:  1.066476: 100%|██████████| 319/319 [00:01<00:00, 182.87it/s]\n",
      "Epoch  13, Train MSE:  1.177484:   6%|▌         | 19/319 [00:00<00:01, 188.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.039785, Test RMSE:  1.019699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  13, Train MSE:  1.070001: 100%|██████████| 319/319 [00:01<00:00, 181.86it/s]\n",
      "Epoch  14, Train MSE:  1.066930:   6%|▌         | 18/319 [00:00<00:01, 175.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.040111, Test RMSE:  1.019858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  14, Train MSE:  1.067758: 100%|██████████| 319/319 [00:01<00:00, 181.34it/s]\n",
      "Epoch  15, Train MSE:  1.152344:   6%|▌         | 19/319 [00:00<00:01, 183.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.040262, Test RMSE:  1.019932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  15, Train MSE:  1.067988: 100%|██████████| 319/319 [00:01<00:00, 183.65it/s]\n",
      "Epoch  16, Train MSE:  1.049952:   6%|▌         | 19/319 [00:00<00:01, 189.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.048863, Test RMSE:  1.024140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  16, Train MSE:  1.068809: 100%|██████████| 319/319 [00:01<00:00, 184.08it/s]\n",
      "Epoch  17, Train MSE:  1.071653:   6%|▌         | 19/319 [00:00<00:01, 188.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.045675, Test RMSE:  1.022582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  17, Train MSE:  1.068938: 100%|██████████| 319/319 [00:01<00:00, 182.89it/s]\n",
      "Epoch  18, Train MSE:  1.136447:   6%|▌         | 18/319 [00:00<00:01, 177.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.049213, Test RMSE:  1.024311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  18, Train MSE:  1.068063: 100%|██████████| 319/319 [00:01<00:00, 182.10it/s]\n",
      "Epoch  19, Train MSE:  1.099667:   6%|▌         | 19/319 [00:00<00:01, 187.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.040970, Test RMSE:  1.020279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  19, Train MSE:  1.066948: 100%|██████████| 319/319 [00:01<00:00, 183.48it/s]\n",
      "Epoch  20, Train MSE:  0.937045:   6%|▌         | 18/319 [00:00<00:01, 179.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.045523, Test RMSE:  1.022508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  20, Train MSE:  1.066575: 100%|██████████| 319/319 [00:01<00:00, 179.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE:  1.040110, Test RMSE:  1.019858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Model(\n",
       "   (lstm): LSTM(300, 300)\n",
       "   (fc1): Linear(in_features=300, out_features=64, bias=True)\n",
       "   (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "   (fc3): Linear(in_features=32, out_features=16, bias=True)\n",
       "   (relu): ReLU()\n",
       "   (fc): Linear(in_features=16, out_features=1, bias=True)\n",
       " ),\n",
       " {'train_losses': [2784.0658946037292,\n",
       "   2735.0329282283783,\n",
       "   2733.943948864937,\n",
       "   2731.4281246066093,\n",
       "   2736.1711765527725,\n",
       "   2730.4401680231094,\n",
       "   2731.5477026700974,\n",
       "   2728.257747769356,\n",
       "   2731.309131503105,\n",
       "   2728.5819034576416,\n",
       "   2724.798883676529,\n",
       "   2719.5133152008057,\n",
       "   2728.503458738327,\n",
       "   2722.781803011894,\n",
       "   2723.369124889374,\n",
       "   2725.462235212326,\n",
       "   2725.7919225096703,\n",
       "   2723.560584664345,\n",
       "   2720.7170582413673,\n",
       "   2719.7651859521866],\n",
       "  'test_losses': [298.76652240753174,\n",
       "   297.1277029514313,\n",
       "   296.7842733860016,\n",
       "   296.5882852077484,\n",
       "   296.2074851989746,\n",
       "   296.07579374313354,\n",
       "   295.8573122024536,\n",
       "   295.5861701965332,\n",
       "   295.6104311943054,\n",
       "   297.16519951820374,\n",
       "   295.4742772579193,\n",
       "   295.29895210266113,\n",
       "   295.39158153533936,\n",
       "   295.4342882633209,\n",
       "   297.8769905567169,\n",
       "   296.97158455848694,\n",
       "   297.9765839576721,\n",
       "   295.6355230808258,\n",
       "   296.9285788536072,\n",
       "   295.3911280632019]})"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelbuild.train(model, train, test, optimizer, criterion, 20, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nlp.disable_pipes():\n",
    "    data_vecs = np.array([nlp(text).vector for text in data['excerpt']])\n",
    "    data_lbls = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp('hello my name is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_texts = [nlp(text) for text in data['excerpt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.zeros((len(nlp_texts), 300, 300))\n",
    "\n",
    "for i in range(len(nlp_texts)):\n",
    "    text = nlp_texts[i]\n",
    "    zeroes[i][0:min(len(text), 300)] = torch.tensor([word.vector for word in text[0:min(len(text), 300)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2834, 300, 300])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_vecs, data_lbls, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.033396832247627"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(np.full((data.shape[0],),data['target'].mean()), data['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'base_score': 0.5,\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 2,\n",
    "    'learning_rate': 0.1,\n",
    "    'verbosity': 1,2\n",
    "    'random_state': random_state\n",
    "}\n",
    "model = xgb.XGBRegressor(objective=\"reg:squarederror\", **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=200, n_jobs=8, num_parallel_tree=1, random_state=1,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=1)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6603736247497498"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
